#!/usr/bin/env python

##############################################################################
##
# Copyright 2019 CELLS / ALBA Synchrotron, Bellaterra, Spain
##
# lnstacks is free software: you can redistribute it and/or modify
# it under the terms of the GNU Lesser General Public License as published by
# the Free Software Foundation, either version 3 of the License, or
# (at your option) any later version.
##
# lnstacks is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
# GNU Lesser General Public License for more details.
##
##############################################################################


""""Script lnstacks is used to get the absorbance stacks, giving as input
the transmittance stacks: apply minus Napierian logarithm to stacks.
It can be applied to hdf5/mrc stacks situated on the same folder.
It can also be applied on individual hdf5/mrc stacks.
Mainly used for processing Tomography projection image stacks, but it is
a generic script."""

import os
import glob
import struct
import argparse
from argparse import RawTextHelpFormatter

import h5py
import mrcfile
import numpy as np
from joblib import Parallel, delayed


class CustomFormatter(argparse.ArgumentDefaultsHelpFormatter,
                      argparse.RawDescriptionHelpFormatter):
    pass


def output_empty_hdf5(outfile_fn, n_frames, n_rows, n_cols, tree, dataset):
    h5_outfile = h5py.File(outfile_fn, 'w')
    grp_ln = h5_outfile.create_group(tree)
    grp_ln.create_dataset(dataset, shape=(n_frames, n_rows, n_cols),
                          chunks=(1, n_rows, n_cols), dtype='float32')
    grp_ln[dataset].attrs['Number of Frames'] = n_frames
    grp_ln[dataset].attrs['Number of Rows'] = n_rows
    grp_ln[dataset].attrs['Number of Columns'] = n_cols
    return h5_outfile, grp_ln


def output_empty_mrc(outfile_fn, n_frames, n_rows, n_cols):
    # Make a new, empty memory-mapped MRC file
    mrc_outfile = mrcfile.new_mmap(outfile_fn,
                                   shape=(n_frames, n_rows, n_cols),
                                   mrc_mode=2,
                                   overwrite=True)
    return mrc_outfile


def copy_h5_metadata(h5_group, h5_grp_ln):
    """Copy metadata to ln stack"""

    # Retrieving Angles
    try:
        angles = h5_group["rotation_angle"].value
        h5_grp_ln.create_dataset("rotation_angle", data=angles)
    except:
        print("\nAngles could not be extracted.")

    # Retrieving Energies
    try:
        energies = h5_group["energy"].value
        h5_grp_ln.create_dataset("energy", data=energies)
    except:
        print("\nEnergies could not be extracted.")

    # Retrieving Pixel Size
    try:
        x_pixel_size = h5_group["x_pixel_size"].value
        y_pixel_size = h5_group["y_pixel_size"].value
        h5_grp_ln.create_dataset("x_pixel_size", data=x_pixel_size)
        h5_grp_ln.create_dataset("y_pixel_size", data=y_pixel_size)
    except Exception:
        print("\nPixel size could NOT be extracted.")


def minus_ln_stack_h5(h5_stack_fn, mrc_out,
                      tree="TomoNormalized", dataset="TomoNormalized"):
    """Minus Napierian logarithm applied to a hdf5 stack of images"""

    h5_handler = h5py.File(h5_stack_fn, "r")
    h5_group = h5_handler[tree]

    # Shape information of data image stack
    infoshape = h5_group[dataset].shape
    n_frames = infoshape[0]
    n_rows = infoshape[1]
    n_cols = infoshape[2]

    # Calculate absorbance (minus logarithm)
    if mrc_out:
        # Calculate absorbance (minus logarithm) stack and store on mrc
        outfile_fn = h5_stack_fn.rsplit('.', 1)[0] + '_ln.mrc'
        mrc_outfile = output_empty_mrc(outfile_fn, n_frames, n_rows, n_cols)
        for n_img in range(n_frames):
            img = h5_group[dataset][n_img]
            mrc_outfile.data[n_img, :, :] = -np.log(img)
        mrc_outfile.flush()
        mrc_outfile.close()
    else:
        # Calculate absorbance (minus logarithm) stack and store on hdf5
        outfile_fn = h5_stack_fn.rsplit('.', 1)[0] + '_ln.hdf5'
        h5_outfile, grp_ln = output_empty_hdf5(
            outfile_fn, n_frames, n_rows, n_cols, tree, dataset)
        copy_h5_metadata(h5_group, grp_ln)
        for n_img in range(n_frames):
            img = h5_group[dataset][n_img]
            # print(-np.log(img[20][25]))
            grp_ln[dataset][n_img] = -np.log(img)
        h5_outfile.close()

    h5_handler.close()

    print("Minus logarithm applied on stack {}".format(h5_stack_fn))


def minus_ln_stack_mrc(mrc_stack_fn, mrc_out,
                       tree="TomoNormalized", dataset="TomoNormalized"):

    mrc_handler = mrcfile.open(mrc_stack_fn, mode='r')

    infoshape = mrc_handler.data.shape
    n_frames = infoshape[0]
    n_rows = infoshape[1]
    n_cols = infoshape[2]

    # Calculate absorbance (minus logarithm)
    if mrc_out:
        # Calculate absorbance (minus logarithm) stack and store on mrc
        outfile_fn = mrc_stack_fn.rsplit('.', 1)[0] + '_ln.mrc'
        mrc_outfile = output_empty_mrc(outfile_fn, n_frames, n_rows, n_cols)
        for n_img in range(n_frames):
            img = mrc_handler.data[n_img, :, :]
            mrc_outfile.data[n_img, :, :] = -np.log(img)
        mrc_outfile.flush()
        mrc_outfile.close()
    else:
        # Calculate absorbance (minus logarithm) stack and store on hdf5
        outfile_fn = mrc_stack_fn.rsplit('.', 1)[0] + '_ln.hdf5'
        h5_outfile, grp_ln = output_empty_hdf5(
            outfile_fn, n_frames, n_rows, n_cols, tree, dataset)
        for n_img in range(n_frames):
            img = mrc_handler.data[n_img, :, :]
            grp_ln[dataset][n_img] = -np.log(img)
        h5_outfile.close()

    print("Minus logarithm applied on stack {}".format(mrc_stack_fn))


def minus_ln_stack(stack_fn, mrc_out,
                   tree="TomoNormalized", dataset="TomoNormalized"):
    """Apply the minus log to a hdf5/mrc stack"""
    ext = stack_fn.rsplit('.', 1)[1]
    if ext == "hdf5" or ext == "h5":
        minus_ln_stack_h5(stack_fn, mrc_out, tree=tree, dataset=dataset)
    elif ext == "mrc":
        minus_ln_stack_mrc(stack_fn, mrc_out, tree=tree, dataset=dataset)


def minus_ln_stacks_dir(directory, mrc_out, tree="TomoNormalized",
                   dataset="TomoNormalized"):
    """Apply the minus Napierian logarithm to many stacks situated
    in the same directory. Parallelization applied: many stacks
    processed in parallel"""

    fnames = glob.glob(directory + "/*")
    print("\nCompute absorbance stacks:\n"
          "Applying minus log to the stacks in"
          " the given directory:\n{0}\n".format(fnames))

    cores = -2
    Parallel(n_jobs=cores, backend="multiprocessing")(
        delayed(minus_ln_stack)(filename, mrc_out,
                                tree, dataset) for filename in fnames)


def main():
    parser = argparse.ArgumentParser(
        description="Compute absorbance stacks (given the "
                    "transmittance stacks) \n"
                    "Apply minus logarithm to: \n" +
                    "- A single stack \n" +
                    "- Many stacks situated in the same folder\n" +
                    "It accepts hdf5 stacks and mrc stacks",
        formatter_class=RawTextHelpFormatter)

    parser.add_argument("input", type=str, default=None,
                        help="Input one of those:\n"
                             "  - File hdf5 (or mrc) stack, \n"
                             "  - Directory containing hdf5 (or mrc) stacks")

    parser.add_argument('-m', '--mrc', type=int, default=1,
                        help='Output stack in mrc: -m=1 (default)\n'
                             'Output stack in hdf5: -m=0')

    args = parser.parse_args()

    if os.path.isfile(args.input):
        print("Applying minus log to {0} stack".format(args.input))
        minus_ln_stack(args.input, args.mrc)

    elif os.path.isdir(args.input):
        minus_ln_stacks_dir(args.input, args.mrc)
    print("")


if __name__ == "__main__":
    main()
